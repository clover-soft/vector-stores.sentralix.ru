# Техническое задание (ТЗ)

## 1. Общие сведения

**Название проекта:** `vector-stores.sentralix.ru`

**Назначение:** сервис управления RAG-базами знаний (файлами, индексами и процессом индексации) по единому API-контракту, независимо от провайдера хранения/индексации.

**Провайдеры (планы интеграции):**
- `yandex`
- `openai`
- `sentralix` (локальный движок проекта)

**База данных:** MariaDB

**Технологический стек:** FastAPI + SQLAlchemy + Docker

---

## 2. Цели и зона ответственности сервиса

### 2.1. Цели
- Предоставить единый HTTP API для:
  - управления файлами доменных баз знаний (загрузка/удаление/обновление метаданных);
  - управления индексами (CRUD);
  - связи файлов с индексами;
  - управления процессом индексации у провайдеров (создание/удаление индекса у провайдера, загрузка файлов в индекс, запуск индексации, опрос статусов, синхронизация статусов в БД).

### 2.2. Границы проекта
- Сервис **не является** UI.
- Сервис **не выполняет** бизнес-авторизацию пользователей (если авторизация нужна — применяется внешняя, но сервис должен обеспечить доменную изоляцию на уровне данных и файлов).
- Сервис предоставляет **API-контракт**, по которому внешний бэкенд сможет управлять базами знаний.

---

## 3. Основные сущности и данные

### 3.1. Таблица `rag_indexes`
DDL (как источник истины):
- `domain_id` — принадлежность домену.
- `provider_type` — `yandex` / `sentralix` / `openai`.
- `external_id` — идентификатор индекса у провайдера.
- `name` — имя индекса (как в OpenAI vector stores).
- `description` — описание индекса.
- `chunking_strategy` — стратегия чанкинга (OpenAI).
- `expires_after` — политика истечения (OpenAI).
- `file_ids` — список идентификаторов файлов провайдера (OpenAI).
- `metadata` — map с дополнительными метаданными (OpenAI).
- `indexing_status` — `not_indexed | in_progress | done | failed`.
- `indexed_at` — время начала последней попытки индексации.

### 3.2. Таблица `rag_files`
DDL (как источник истины):
- `file_name`, `file_type`, `local_path`, `size_bytes`.
- `external_file_id`, `external_uploaded_at` — при наличии загрузки в провайдера.
- `chunking_strategy` — стратегия чанкинга (OpenAI). Если не задана, используется `auto`.
- `domain_id`.
- `tags` — JSON.
- `notes`.

### 3.3. Таблица `rag_index_files`
DDL (как источник истины):
- `index_id`, `file_id`.
- `include_order` — порядок включения.

### 3.4. Доменная изоляция
**Ключевой принцип:** любые операции (файлы, индексы, связи) выполняются строго в рамках `domain_id`.
- Все запросы к API должны содержать `domain_id` (предпочтительно в заголовке, например `X-Domain-Id`, либо в URL/теле; вариант должен быть единым для всех ручек).
- Любые выборки из БД фильтруются по `domain_id`.
- Файловая система изолируется по `domain_id`.

---

## 4. Архитектура и слои

### 4.1. Точка входа
- `main.py` — единая точка входа.

### 4.2. Слой API (ручки)
- Принимает и валидирует запросы.
- Не содержит бизнес-логики доступа к БД напрямую.
- Взаимодействует **исключительно** с сервисами.
- Полностью документируется в Swagger (FastAPI OpenAPI).

### 4.3. Слой Pydantic-схем
- Отдельная папка со схемами запросов/ответов.
- Схемы должны быть согласованы с API-контрактом.

### 4.4. Модели (SQLAlchemy)
- Модели лежат в отдельной папке.
- Отражают DDL (поля/типы/индексы/enum).

### 4.5. Сервисный слой
- Сервисы реализуют CRUD и бизнес-операции.
- Разделение ответственности:
  - сервисы файлов;
  - сервисы индексов;
  - сервис связки индекс↔файл;
  - сервис индексации/оркестрации (pipeline отложенной индексации);
  - сервис провайдеров (выбор интеграции по `provider_type`, фасадный доступ).

### 4.6. Интеграция с провайдерами
- Каждая интеграция — в отдельной папке.
- Каждая интеграция предоставляет **один фасад** (точка входа).
- Все фасады должны реализовывать единый контракт (интерфейс/базовый класс).

### 4.7. Доступ к базе
- Сервисы взаимодействуют с БД через единый класс-провайдер базы данных (например `database.py`).
- Используется SQLAlchemy.

### 4.8. Единый класс логирования
- В проекте должен быть единый класс/модуль логирования.
- Логи пишутся согласно переменным окружения.

---

## 5. Структура проекта (ориентир)

Требование: использовать подготовленную структуру папок.

Ожидаемая структура (может уточняться при реализации):
- `main.py`
- `config.py` (импорт настроек из env)
- `database.py` (инициализация SQLAlchemy, сессии)
- `app/`
  - `api/` (роутеры FastAPI)
  - `schemas/` (Pydantic)
  - `models/` (SQLAlchemy модели)
  - `services/` (бизнес-логика)
  - `utils/` (логгер, вспомогательные утилиты)
  - `providers/` (интеграции)
    - `base.py`
    - `yandex/`
    - `openai/`
    - `sentralix/`
- `docs/`
  - `migrations/` (миграции, по требованию проекта)

---

## 6. Конфигурация и переменные окружения

Принцип: **никакого хардкода**. Все параметры — через env и `config.py`.

Минимальный набор (может расширяться):
- `DATABASE_URI` — строка подключения SQLAlchemy.
- `LOG_LEVEL` — уровень логов.
- `LOG_FORMAT` — формат логов.
- `LOG_FILE` — путь к файлу логов.
- `LOG_TO_CONSOLE` — писать ли в stdout.
- `RUNNING_IN_CONTAINER` — признак запуска в Docker.
- `ALLOW_HOSTS` — список разрешённых хостов/адресов (если используется middleware).

Провайдеры:
- Yandex:
  - `YC_FOLDER_ID`
  - `YC_SA_KEY_JSON_B64`
- OpenAI:
  - `OPENAI_API_KEY` (и прочие параметры при необходимости)
- Sentralix:
  - параметры локального движка (уточняются).

---

## 7. Docker и окружение

### 7.1. Запуск
- Сервис запускается в Docker.
- В контейнер пробрасываются volume:
  - `/app` — код
  - `/var/log` — логи
  - `/files` — хранилище файлов

### 7.2. Хранилище файлов
- Все файлы хранятся в `/files` внутри Docker.
- Для каждого домена — отдельная подпапка:
  - `/files/<domain_id>/...`

Рекомендация по структуре хранения:
- `/files/<domain_id>/<rag_file_id>/original/<file_name>`

Требования:
- При загрузке вычисляется `size_bytes`.
- В БД хранится `local_path` (абсолютный путь в контейнере либо путь относительно `/files`, фиксируется единообразно).

---

## 8. API-контракт (черновой, для детализации)

**Базовый префикс:** `/api/v1`

**Доменная идентификация:**
- обязательно передаётся `domain_id` (например заголовок `X-Domain-Id`).

### 8.1. Service health
- `GET /health`
  - Проверка, что сервис поднят.
  - Возвращает статус и версию.

### 8.2. CRUD файлов
- `POST /files` (multipart upload)
  - загрузка файла в `/files/<domain_id>/...`
  - создание записи `rag_files`
  - опционально: `chunking_strategy` (JSON-объект, передаётся как строка в multipart)
- `GET /files`
  - список файлов домена
- `GET /files/{file_id}`
  - получение метаданных
- `GET /files/{file_id}/download`
  - скачивание
- `PATCH /files/{file_id}`
  - изменение `tags`, `notes`, `chunking_strategy` (опционально `file_name` если допускается)
- `DELETE /files/{file_id}`
  - удаление записи и физического файла

### 8.3. CRUD индексов
- `POST /indexes`
  - создание локального индекса (в БД)
- `GET /indexes`
  - список индексов домена
- `GET /indexes/{index_id}`
  - детали индекса
- `PATCH /indexes/{index_id}`
  - изменение параметров (включая `name`, `description`, `chunking_strategy`, `expires_after`, `file_ids`, `metadata`)
- `DELETE /indexes/{index_id}`
  - удаление локального индекса

### 8.4. Связь файл ↔ индекс
- `POST /indexes/{index_id}/files/{file_id}`
  - привязка файла к индексу (создание `rag_index_files`)
- `DELETE /indexes/{index_id}/files/{file_id}`
  - отвязка
- `GET /indexes/{index_id}/files`
  - список файлов, включённых в индекс

### 8.5. Провайдерные операции (проверка состояния)
- `GET /providers/{provider_type}/indexes`
  - проверка текущих индексов в провайдере (внешний список)

---

## 9. Единый контракт провайдера

### 9.1. Требование
Интеграции провайдеров должны иметь единый контракт, реализованный как базовый класс/интерфейс (например `BaseRagProvider`).

### 9.2. Минимальные методы контракта (ориентир)
- `list_indexes(domain_id: str) -> list[ProviderIndex]`
- `create_index(index_payload) -> ProviderCreatedIndex` (возвращает `external_id`)
- `delete_index(external_id: str) -> None`
- `get_index(external_id: str) -> ProviderIndex`
- `upload_file(domain_id: str, local_path: str, meta) -> ProviderFile` (если у провайдера требуется отдельная загрузка)
- `attach_file_to_index(external_index_id: str, external_file_id: str | None, local_path: str, meta) -> None`
- `start_indexing(external_index_id: str) -> ProviderIndexingRun`
- `get_indexing_status(external_index_id: str) -> ProviderIndexingStatus`

Примечание: конкретная реализация зависит от возможностей провайдера. Если провайдер не поддерживает отдельную «загрузку файла», допускается схема, когда файл прикрепляется напрямую из `local_path`.

---

## 10. Отложенная индексация (pipeline)

### 10.1. Назначение
Обеспечить асинхронный процесс подготовки индекса у провайдера и запуска индексации на основе файлов, привязанных к индексу.

### 10.2. Сценарий (обязательные шаги)
1. Создание индекса у провайдера.
2. Получение `external_id` и сохранение его в `rag_indexes.external_id`.
3. Подгрузка/прикрепление файлов к индексу (по `rag_index_files`).
4. Запуск индексации.
5. Проверка статуса индексации (polling).
6. Обновление `rag_indexes.indexing_status` и `indexed_at` в локальной базе.
7. Удаление индекса у провайдера (при удалении локального индекса или по TTL/явному запросу).

### 10.3. Статусы
Статус в локальной БД должен соответствовать enum:
- `not_indexed`
- `in_progress`
- `done`
- `failed`

### 10.4. Технические требования к реализации
- Процесс должен быть идемпотентным на уровне API (повторный вызов не должен ломать состояние).
- Все операции должны логироваться (с `request_id`, если используется).
- Ошибки провайдера должны приводить к обновлению `indexing_status = failed` и сохранению диагностической информации в логах.

---

## 11. Документирование Swagger

Требования:
- Все ручки должны иметь:
  - описание;
  - примеры;
  - коды ответов;
  - схемы ошибок.
- Для ошибок рекомендуется единый формат ответа (например `error_code`, `message`, `details`, `request_id`).

---

## 12. Миграции

Требование проекта: миграции хранятся в папке `docs/`.

Предлагаемая структура:
- `docs/migrations/` — миграции (например Alembic), либо SQL-скрипты

Правила:
- DDL в ТЗ является источником истины.
- При реализации миграций — обеспечить воспроизводимость развёртывания.

---

## 13. Пошаговая реализация (этапы)

### Этап 1: Каркас FastAPI + Docker + логирование
- **Цель:** поднять сервис в Docker, получить `/health`, убедиться, что логи пишутся.
- **Действия:**
  - добавить `main.py` с FastAPI приложением;
  - подключить единый логгер;
  - добавить конфиг `config.py` и чтение env;
  - реализовать `GET /health`;
  - убедиться, что контейнер стартует с текущим `Dockerfile`.
- **Ожидаемый результат:** сервис доступен, Swagger открывается, health отвечает.
- **Definition of Done:**
  - `docker-compose up` поднимает сервис без ошибок;
  - `GET /health` возвращает `200`;
  - в `/var/log` пишутся логи согласно env.

### Этап 2: CRUD файлов (доменные файлы)
- **Цель:** управлять файлами базы знаний, хранить их в `/files/<domain_id>/...`.
- **Действия:**
  - SQLAlchemy модель `rag_files` + сервис CRUD;
  - API ручки загрузки/чтения/обновления/удаления;
  - сохранение файлов в `/files` с доменной изоляцией;
  - валидация `file_type`, размер, корректное заполнение `size_bytes`.
- **Ожидаемый результат:** внешний бэкенд может полностью управлять файлами домена.
- **Definition of Done:**
  - загрузка создаёт запись в БД и файл на диске;
  - удаление удаляет запись и файл;
  - список и получение метаданных фильтруются по `domain_id`.

### Этап 3: CRUD индексов + связь индекс↔файл
- **Цель:** управлять индексами и привязкой файлов.
- **Действия:**
  - SQLAlchemy модель `rag_indexes` + CRUD сервис;
  - SQLAlchemy модель `rag_index_files` + сервис связей;
  - API ручки CRUD индексов;
  - API ручки привязки/отвязки файлов к индексу.
- **Ожидаемый результат:** индекс и его состав (набор файлов) управляются в локальной БД.
- **Definition of Done:**
  - связи индекс↔файл корректно создаются/удаляются;
  - все операции доменно изолированы;
  - Swagger задокументирован.

### Этап 4: Интеграции провайдеров (проверка текущих индексов)
- **Цель:** реализовать слой провайдеров и возможность проверять состояние у провайдера.
- **Действия:**
  - создать базовый контракт провайдера;
  - реализовать фасады `yandex`, `openai`, `sentralix`;
  - сервис-роутер провайдеров (выбор по `provider_type`);
  - ручка `GET /providers/{provider_type}/indexes`.
- **Ожидаемый результат:** сервис умеет ходить в провайдера и возвращать список индексов.
- **Definition of Done:**
  - единый контракт реализован всеми провайдерами;
  - конфиг провайдеров только через env;
  - ошибки провайдера корректно обрабатываются и логируются.

### Этап 5: Отложенная индексация (полный цикл)
- **Цель:** автоматизировать создание индекса у провайдера и индексацию файлов.
- **Действия:**
  - сервис оркестрации индексации:
    - создать индекс у провайдера → сохранить `external_id`;
    - прикрепить файлы к индексу;
    - запустить индексацию;
    - опрашивать статус;
    - обновлять `indexing_status` в `rag_indexes`;
    - удалять индекс у провайдера по запросу/удалению локального индекса.
  - API ручки для запуска индексации и просмотра статуса (формат уточняется при реализации).
- **Ожидаемый результат:** один вызов API запускает процесс, дальше статус можно получать из БД.
- **Definition of Done:**
  - `external_id` проставляется автоматически;
  - `indexing_status` переходит по стадиям и соответствует реальности у провайдера;
  - при ошибках ставится `failed`, есть диагностические логи;
  - доменная изоляция соблюдена.

---

## 14. Критерии приёмки (общие)
- API стабильно работает в Docker.
- Нет хардкода конфигурации — всё через env + `config.py`.
- Все операции доменно изолированы.
- Хранение файлов соответствует требованиям `/files/<domain_id>/...`.
- Swagger подробно документирован.
- Слой провайдеров реализован как единый контракт.
- Отложенная индексация обновляет статусы в локальной БД.
